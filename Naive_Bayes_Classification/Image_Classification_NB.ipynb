{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use torch vision to handle the load of the entire MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = torchvision.datasets.MNIST(root='./data', train=True, transform=None, target_transform=None, download=True)\n",
    "data_eval = torchvision.datasets.MNIST(root='./data', train=False, transform=None, target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the train & evaluation sets to numpy arrays for manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_raw = data_train.data.numpy()\n",
    "train_labels = data_train.targets.numpy()\n",
    "eval_images_raw = data_eval.data.numpy()\n",
    "eval_labels = data_eval.targets.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chcecking the shapes of the train & evaluation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images_raw.shape)\n",
    "print(eval_images_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with images, pixel formats are stored in an 8-bit integer, whose values range between 0 and 255, where 0 is completely dark (or black), and 255 is white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_raw.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_raw[0].min(), train_images_raw[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,), (10000,), dtype('int64'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape, eval_labels.shape, train_labels.dtype, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing sanity check on the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking an individual image, and the type of array we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 18, 18, 18, 126, 136, 175, 26, 166, 255, 247, 127, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 30, 36, 94, 154, 170, 253, 253, 253, 253, 253, 225, 172, 253, 242, 195, 64, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 49, 238, 253, 253, 253, 253, 253, 253, 253, 253, 251, 93, 82, 82, 56, 39, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 18, 219, 253, 253, 253, 253, 253, 198, 182, 247, 241, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 80, 156, 107, 253, 253, 205, 11, 0, 43, 154, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 1, 154, 253, 90, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 139, 253, 190, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 190, 253, 70, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 241, 225, 160, 108, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 81, 240, 253, 253, 119, 25, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 186, 253, 253, 150, 27, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 93, 252, 253, 187, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 249, 253, 249, 64, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 46, 130, 183, 253, 253, 207, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 148, 229, 253, 253, 253, 250, 182, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 114, 221, 253, 253, 253, 253, 201, 78, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 23, 66, 213, 253, 253, 253, 253, 198, 81, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 18, 171, 219, 253, 253, 253, 253, 195, 80, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 55, 172, 226, 253, 253, 253, 253, 244, 133, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 136, 253, 253, 253, 212, 135, 132, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc4e15fde48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeCIvxAUP8PRZ8Vlgh2BcUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc558672390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for row_img in train_images_raw[0]:\n",
    "    print(row_img.tolist())\n",
    "    \n",
    "plt.imshow(train_images_raw[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applying a threshold, we extract the darkest pixels based on the established benchmark, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thresholded(images_raw, threshold):\n",
    "    \"\"\"\n",
    "    Perform image thresholding.\n",
    "\n",
    "    Parameters:\n",
    "            images_raw (np,array): Do not assume anything about its shape, dtype or range of values. \n",
    "            Your function should be careless about these attributes.\n",
    "            threshold (int): A scalar value.\n",
    "\n",
    "    Returns:\n",
    "            threshed_image (np.array): A numpy array with the same shape as images_raw, and the bool dtype. \n",
    "            This array should indicate whether each elemelent of images_raw is greater than or equal to \n",
    "            threshold.\n",
    "    About the return array:\n",
    "     A numpy array with the same shape as `images_raw`, and the `bool` dtype. This array should \n",
    "     indicate whether each elemelent of `images_raw` is **greater than or equal to**  `threshold`.\n",
    "                \n",
    "    \"\"\"    \n",
    "\n",
    "    threshed_image = images_raw >= threshold\n",
    "   \n",
    "    \n",
    "    return threshed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc570c335c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA30AAAEZCAYAAAAjcEzcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc5307bd160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.imshow(train_images_raw[0], cmap='Greys')\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.imshow(train_images_threshed[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_threshed = get_thresholded(train_images_raw, threshold=20)\n",
    "eval_images_threshed = get_thresholded(eval_images_raw, threshold=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a proper image classification, we need to do some data fansformations that include to resize the images, and test the Naive Bayes algorithm with the image as is, a bounding box, or a stretched image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Bonding-Box image preprocessing: For this task, we need to find the rows and columns with any dark pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_is_row_inky(images):\n",
    "    \"\"\"\n",
    "    Finds the rows with ink pixels.\n",
    "\n",
    "        Parameters:\n",
    "        images (np,array): A numpy array with the shape (N, height, width)\n",
    "\n",
    "        Returns:\n",
    "        is_row_inky (np.array): A numpy array with the shape (N, height), and the bool dtype. \n",
    "        \n",
    "        is_row_inky: A numpy array with the shape `(N, height)`, and the `bool` dtype. \n",
    "    is_row_inky[i,j] should be True if **any** of the pixels in the `j`th row of the \n",
    "    `i`th image was an ink pixel, and False otherwise.\n",
    "    \n",
    "    images = N * h * w\n",
    "    \n",
    "    \"\"\"\n",
    "    is_row_inky = images.sum(axis=2) >=1\n",
    "    \n",
    "    \n",
    "    return is_row_inky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the columns with dark pixels is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_is_col_inky(images):\n",
    "    \"\"\"\n",
    "    Finds the columns with ink pixels.\n",
    "\n",
    "        Parameters:\n",
    "        images (np.array): A numpy array with the shape (N,height,width).\n",
    "                \n",
    "        Returns:\n",
    "        is_col_inky (np.array): A numpy array with the shape (N, width), and the bool dtype. \n",
    "        \n",
    "        is_col_inky[i,j] should be True if **any** of the pixels in the `j`th column of the \n",
    "        `i`th image was an ink pixel, and False otherwise.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    is_col_inky = images.sum(axis=1) >= 1\n",
    "\n",
    "    return is_col_inky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to crop the box, I need to find what is the first dark row containing dark pixels, through the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_ink_row_index(is_row_inky):\n",
    "    \"\"\"\n",
    "     Finds the first row containing ink pixels\n",
    "\n",
    "        Parameters:\n",
    "        is_row_inky (np.array): A numpy array with the shape (N, height), and the bool dtype. \n",
    "        This is the output of the get_is_row_inky function that you implemented before.\n",
    "                \n",
    "        Returns:\n",
    "        first_ink_rows (np.array): A numpy array with the shape (N,), and the int64 dtype.\n",
    "        \n",
    "        first_ink_rows[i]` is the index of the first row containing any ink pixel in the \n",
    "        `i`th image. The indices should be **zero-based**.\n",
    "        In other words, get the index of the first row, for all rows in the array\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    first_ink_rows = np.argmax(is_row_inky, axis=1)\n",
    "    \n",
    "    return first_ink_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar fashion, we can follow the same data structure to extract the first dark pixels indices for all columns. Like we did in the previous function, we use the return array(is_col_inky) from the get_is_col_inky function implemented before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_ink_col_index(is_col_inky):\n",
    "    return get_first_ink_row_index(is_col_inky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's just find the last row containing dark pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_ink_row_index(is_row_inky):\n",
    "    \"\"\"\n",
    "    Finds the last row containing ink pixels.\n",
    "\n",
    "        Parameters:\n",
    "        is_row_inky (np.array): A numpy array with the shape (N, height), and the bool dtype. \n",
    "        This is the output of the get_is_row_inky function that you implemented before.\n",
    "                \n",
    "        Returns:\n",
    "        last_ink_rows (np.array): A numpy array with the shape (N,), and the int64 dtype.\n",
    "        \n",
    "        `last_ink_rows[i]` is the index of the last row containing any ink pixel in the \n",
    "        `i`th image. The indices should be **zero-based**.\n",
    "        \n",
    "    \"\"\"    \n",
    "\n",
    "#     j = np.transpose(np.nonzero(is_row_inky))\n",
    "#     k = np.unique(j, axis=0)\n",
    "#     k = np.array(k)\n",
    "    \n",
    "#     j_idx = np.lexsort(k[:,[1,0]].T)\n",
    "#     idx = np.append(np.flatnonzero(k[1:,0] > k[:-1,0]), k.shape[0]-1)\n",
    "#     res_matrix = k[j_idx[idx]]\n",
    "#     last_ink_rows = res_matrix[:,1]\n",
    "\n",
    "    # don't need lexsort though\n",
    "    k = np.transpose(np.nonzero(is_row_inky))\n",
    "    idx = np.append(np.flatnonzero(k[1:,0] > k[:-1,0]), k.shape[0]-1)\n",
    "    last_ink_rows = k[idx, 1]\n",
    "    \n",
    "    return last_ink_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we get the last column containing dark pixeks, following the same data structure as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_ink_col_index(is_col_inky):\n",
    "    return get_last_ink_row_index(is_col_inky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Bounding Box Pre-Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the **inky middle row/column** of the raw image.\n",
    "\n",
    " * The **inky middle row** of the raw image is $r_m = \\lfloor \\frac{r_1 + r_2 + 1}{2} \\rfloor$. In this example, we have $r_m=16$, which is also shown in the picture.\n",
    " * The **inky middle column** of the raw image is $c_m = \\lfloor \\frac{c_1 + c_2 + 1}{2} \\rfloor$. In this example, we have $c_m=13$, which is also shown in the picture.\n",
    "\n",
    "\n",
    "The middle row index of the output image is $r_{out} = \\lfloor \\frac{\\text{bb_size}}{2} \\rfloor$. Similarly, we have the middle column index of the output image $c_{out} = \\lfloor \\frac{\\text{bb_size}}{2} \\rfloor$. In this example, we have $r_{out}=c_{out}=10$, which are marked with blue boxes in the solution image.\n",
    "\n",
    "The **middle inky pixel of the raw image** is `X[r_m, c_m]`. This middle inky pixel is colored red in the raw image for clarification.\n",
    "\n",
    "The **middle inky pixel of the solution image** is `Y[r_out, c_out]`. This middle inky pixel is colored red in the solution image for clarification\n",
    "\n",
    "We shift the raw image in a way that the **middle inky pixel of the raw image** gets placed on the **middle inky pixel of the solution image**. In other words, the red pixels should be placed on top of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_bb(images, bb_size=20):\n",
    "    \"\"\"\n",
    "    Applies the \"Bounding Box\" pre-processing step to images.\n",
    "\n",
    "        Parameters:\n",
    "                images (np.array): A numpy array with the shape (N,height,width)\n",
    "                \n",
    "        Returns:\n",
    "                images_bb (np.array): A numpy array with the shape (N,bb_size,bb_size), \n",
    "                and the same dtype as images. \n",
    "    \"\"\"\n",
    "    \n",
    "    if len(images.shape)==2:\n",
    "        # In case a 2d image was given as input, we'll add a dummy dimension to be consistent\n",
    "        images_ = images.reshape(1,*images.shape)\n",
    "    else:\n",
    "        # Otherwise, we'll just work with what's given\n",
    "        images_ = images\n",
    "        \n",
    "    is_row_inky = get_is_row_inky(images_)\n",
    "    is_col_inky = get_is_col_inky(images_)\n",
    "    \n",
    "    first_ink_rows = get_first_ink_row_index(is_row_inky)\n",
    "    last_ink_rows = get_last_ink_row_index(is_row_inky)\n",
    "    first_ink_cols = get_first_ink_col_index(is_col_inky)\n",
    "    last_ink_cols = get_last_ink_col_index(is_col_inky)\n",
    "    \n",
    "    \n",
    "    r_m = (first_ink_rows + last_ink_rows + 1) // 2\n",
    "    c_m = (first_ink_cols + last_ink_cols + 1) // 2\n",
    "    \n",
    "    r_out = bb_size // 2\n",
    "    c_out = bb_size // 2\n",
    "    \n",
    "    images_bb = []\n",
    "    for i, img in enumerate(images):\n",
    "        img = np.roll(img, (r_out - r_m[i], c_out - c_m[i]), axis=(0, 1))\n",
    "        img = img[:bb_size, :bb_size]\n",
    "        images_bb.append(img)\n",
    "    images_bb = np.array(images_bb)\n",
    "    \n",
    "    \n",
    "    if len(images.shape)==2:\n",
    "        # In case a 2d image was given as input, we'll get rid of the dummy dimension\n",
    "        return images_bb[0]\n",
    "    else:\n",
    "        # Otherwise, we'll just work with what's given\n",
    "        return images_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_bb = get_images_bb(train_images_threshed)\n",
    "eval_images_bb = get_images_bb(eval_images_threshed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing implementation on first image to construct a bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc5309f39e8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA30AAAEZCAYAAAAjcEzcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc540150ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.imshow(train_images_raw[0], cmap='Greys')\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.imshow(train_images_bb[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buiding a the final Stretched Bounding-Box Pre-processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stretched bounding-box should find a tight-canvas of the inky area in each input image, and stretch it out to fill the full height and width of the output bounding-box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_sbb(images, bb_size=20):\n",
    "    \"\"\"\n",
    "    Applies the \"Stretched Bounding Box\" pre-processing step to images.\n",
    "\n",
    "        Parameters:\n",
    "                images (np.array): A numpy array with the shape (N,height,width)\n",
    "                \n",
    "        Returns:\n",
    "                images_sbb (np.array): A numpy array with the shape (N,bb_size,bb_size), \n",
    "                and the same dtype and the range of values as images. \n",
    "    \"\"\"\n",
    "    \n",
    "    if len(images.shape)==2:\n",
    "        # In case a 2d image was given as input, we'll add a dummy dimension to be consistent\n",
    "        images_ = images.reshape(1,*images.shape)\n",
    "    else:\n",
    "        # Otherwise, we'll just work with what's given\n",
    "        images_ = images\n",
    "        \n",
    "    is_row_inky = get_is_row_inky(images)\n",
    "    is_col_inky = get_is_col_inky(images)\n",
    "    \n",
    "    first_ink_rows = get_first_ink_row_index(is_row_inky)\n",
    "    last_ink_rows = get_last_ink_row_index(is_row_inky)\n",
    "    first_ink_cols = get_first_ink_col_index(is_col_inky)\n",
    "    last_ink_cols = get_last_ink_col_index(is_col_inky)\n",
    "    \n",
    "    images_sbb = []\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        img = img[first_ink_rows[i]:last_ink_rows[i] + 1, first_ink_cols[i]:last_ink_cols[i] +1]\n",
    "        img = resize(img,[bb_size, bb_size], preserve_range=True)\n",
    "        images_sbb.append(img)\n",
    "        \n",
    "    images_sbb = np.array(images_sbb, dtype=images.dtype)\n",
    "\n",
    "        \n",
    "    if len(images.shape)==2:\n",
    "        # In case a 2d image was given as input, we'll get rid of the dummy dimension\n",
    "        return images_sbb[0]\n",
    "    else:\n",
    "        # Otherwise, we'll just work with what's given\n",
    "        return images_sbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josenoriegaportilla/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/josenoriegaportilla/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "train_images_sbb = get_images_sbb(train_images_threshed)\n",
    "eval_images_sbb = get_images_sbb(eval_images_threshed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc530666128>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc5587400b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACFCAYAAABL2gNbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCV0ERFHKKGLiDji/+2pfnm+LjijAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc558740be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(30,30))\n",
    "\n",
    "fig, axarr = plt.subplots(1,3) \n",
    "\n",
    "axarr[0].imshow(train_images_raw[0], cmap='Greys')\n",
    "axarr[1].imshow(train_images_sbb[0], cmap='Greys')\n",
    "axarr[2].imshow(train_images_bb[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Performances on Transformed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nb_eval_acc(train_images, train_labels, eval_images, eval_labels, density_model='Gaussian'):\n",
    "    \"\"\"\n",
    "    Trains Naive Bayes models, apply the model, and return an accuracy.\n",
    "\n",
    "        Parameters:\n",
    "                train_images (np.array): A numpy array with the shape (N,height,width)\n",
    "                train_labels (np.array): A numpy array with the shape (N,), where N is the number of samples and \n",
    "                has the int64 dtype.\n",
    "                eval_images (np.array): The evaluation images with similar characteristics to train_images.\n",
    "                eval_labels (np.array): The evaluation labels with similar characteristics to train_labels.\n",
    "                density_model (string): A string that is either 'Gaussian' or 'Bernoulli'. \n",
    "                \n",
    "        Returns:\n",
    "                eval_acc (np.float): a floating number scalar between 0 and 1 that \n",
    "                represents the accuracy of the trained model on the evaluation data.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert density_model in ('Gaussian', 'Bernoulli')\n",
    "    \n",
    "    train_images = train_images.reshape(train_images.shape[0], -1)\n",
    "    eval_images = eval_images.reshape(eval_images.shape[0], -1)\n",
    "    \n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    \n",
    "    # Train model X_train, Y_train\n",
    "    gnb.fit(train_images, train_labels)\n",
    "    \n",
    "    # Predict Y labels\n",
    "    y_hat = gnb.predict(eval_images)\n",
    "    \n",
    "    # Evaluate Accuracy\n",
    "    \n",
    "    eval_acc = (eval_labels == y_hat).mean()\n",
    "    \n",
    "    return eval_acc\n",
    "\n",
    "# Don't mind the following lines and do not change them\n",
    "train_nb_eval_acc_gauss = lambda *args, **kwargs: train_nb_eval_acc(*args, density_model='Gaussian', **kwargs)\n",
    "train_nb_eval_acc_bern = lambda *args, **kwargs: train_nb_eval_acc(*args, density_model='Bernoulli', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Gaussian</th>\n",
       "      <th>Bernoulli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Untouched images</td>\n",
       "      <td>0.5491</td>\n",
       "      <td>0.5491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bounding box</td>\n",
       "      <td>0.7209</td>\n",
       "      <td>0.7209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stretched bounding box</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>0.8150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Accuracy  Gaussian  Bernoulli\n",
       "0        Untouched images    0.5491     0.5491\n",
       "1            Bounding box    0.7209     0.7209\n",
       "2  Stretched bounding box    0.8150     0.8150"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance on untouched images\n",
    "acc_nbg_thr = train_nb_eval_acc(train_images_threshed, train_labels, \n",
    "                                eval_images_threshed, eval_labels, density_model='Gaussian')\n",
    "acc_nbb_thr = train_nb_eval_acc(train_images_threshed, train_labels, \n",
    "                                eval_images_threshed, eval_labels, density_model='Bernoulli')\n",
    "\n",
    "# Performance on bounding-box\n",
    "acc_nbg_bb = train_nb_eval_acc(train_images_bb, train_labels, \n",
    "                                eval_images_bb, eval_labels, density_model='Gaussian')\n",
    "acc_nbb_bb = train_nb_eval_acc(train_images_bb, train_labels, \n",
    "                                eval_images_bb, eval_labels, density_model='Bernoulli')\n",
    "\n",
    "# Performance on stretched bounding-box\n",
    "acc_nbg_sbb = train_nb_eval_acc(train_images_sbb, train_labels, \n",
    "                                eval_images_sbb, eval_labels, density_model='Gaussian')\n",
    "acc_nbb_sbb = train_nb_eval_acc(train_images_sbb, train_labels, \n",
    "                                eval_images_sbb, eval_labels, density_model='Bernoulli')\n",
    "\n",
    "\n",
    "df = pd.DataFrame([('Untouched images', acc_nbg_thr, acc_nbb_thr),\n",
    "                   ('Bounding box', acc_nbg_bb, acc_nbb_bb),\n",
    "                   ('Stretched bounding box', acc_nbg_sbb, acc_nbb_sbb)\n",
    "                  ], columns = ['Accuracy' , 'Gaussian', 'Bernoulli'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Even though Naive Bayes is a very traditional algorithm, it is very powerful for classification. Unlike other algorithms, such as Nearest Neighbors, in which sample size needs to be large enough to be effective and very sensitive to incomplete data, Naive Bayes is a great technique to make probabilistic predictions. Among other benefits, Naibe Bayes classifiers are easy to implement, they are very robust to incomplete data, they are very effective with high dimensional data, and most importantly they are competitive against other techniques, such as neural networks, and decison trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the more data transformation we apply to images, the better the accuracy we get for making predictions, regardless of the probability distribution - in this case whether it is Gaussian or Bernoulli"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
